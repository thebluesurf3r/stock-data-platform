ğŸ“ˆ Stock Market Data Engineering & ML Platform

An end-to-end, production-style data engineering platform that ingests stock market data, processes it incrementally using Apache Spark, engineers features, trains machine learning models, and serves predictions via an API â€” all orchestrated with CI/CD.

This project is designed to demonstrate real-world Data Engineering practices.

ğŸ§  Problem Statement

Stock market data is:

High volume

Time-series based

Continuously arriving

Used by downstream ML systems

This project solves the problem of building a scalable, incremental, and ML-ready data platform on a local system, without relying on paid cloud services.

ğŸ—ï¸ Architecture Overview
Raw CSV Data
    â†“
Ingestion Layer (OOP, Validation)
    â†“
Raw Zone (Partitioned Parquet)
    â†“
Processing Layer (Spark, Incremental)
    â†“
Curated Zone (Daily Prices)
    â†“
Feature Engineering (Technical Indicators)
    â†“
ML Training (scikit-learn)
    â†“
Model Registry (Versioned Artifacts)
    â†“
Prediction API (FastAPI)

1.1 Architecture Diagram (Text â†’ Visual)
![Architecture](docs/architecture.png)
ğŸ“ Logical Architecture
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚   CSV Stock Data     â”‚
                  â”‚ (Local / External)   â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ Ingestion Layer (Python) â”‚
                â”‚  - Validation            â”‚
                â”‚  - OOP Ingestors         â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Raw Zone (Parquet, Partitioned)        â”‚
        â”‚ data/raw/stocks/symbol=...              â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Processing Layer (Spark)                â”‚
        â”‚  - Incremental Processing               â”‚
        â”‚  - Metadata Watermarks                  â”‚
        â”‚  - Partition Pruning                    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Curated Zone (Daily Prices)             â”‚
        â”‚ data/curated/stocks/daily_prices        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Feature Engineering (Spark)             â”‚
        â”‚  - Returns                              â”‚
        â”‚  - Moving Averages                      â”‚
        â”‚  - Volatility                           â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Feature Store (Indicators)              â”‚
        â”‚ data/curated/stocks/indicators          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ ML Training (scikit-learn)              â”‚
        â”‚  - Logistic Regression                  â”‚
        â”‚  - Versioned Artifacts                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Model Registry                          â”‚
        â”‚ models/stock_direction/v1               â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ FastAPI Inference Service               â”‚
        â”‚  - /health                              â”‚
        â”‚  - /predict                             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ§± Tech Stack
Data Engineering

Python

Apache Spark (PySpark)

Parquet

Partitioning & Partition Pruning

Incremental Processing with Metadata

Machine Learning

scikit-learn

Feature engineering with Spark window functions

Logistic Regression (baseline model)

Versioned model artifacts

DevOps / CI-CD

Jenkins

Bash-based orchestration scripts

Virtual environments

Git & GitHub

Serving

FastAPI

Model loaded once at startup

Stateless prediction API

ğŸ“ Project Structure
.
â”œâ”€â”€ Jenkinsfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_ingestion.sh
â”‚   â”œâ”€â”€ run_processing.sh
â”‚   â”œâ”€â”€ run_indicators.sh
â”‚   â”œâ”€â”€ run_training.sh
â”‚   â””â”€â”€ smoke_tests.sh
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ processing/
â”‚   â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ serving/
â”‚   â”œâ”€â”€ utils/
â”‚   â””â”€â”€ validation/
â””â”€â”€ test.py


âš ï¸ Data, models, and virtual environments are intentionally excluded from version control.

ğŸ”„ Incremental Processing Strategy

The pipeline uses metadata-driven watermarks to ensure:

Only new data is processed

Jobs are idempotent

Safe re-runs without duplication

Full-refresh mode available via CLI flags

Example:

python -m src.processing.clean_prices_job --symbol INFY
python -m src.processing.clean_prices_job --symbol INFY --full-refresh

ğŸ“Š Feature Engineering

Technical indicators are computed using Spark window functions, including:

Daily returns

Moving averages (7, 14, 30)

Rolling volatility

These features are:

Computed incrementally

Partitioned by symbol / year / month

Optimized for downstream ML workloads

ğŸ¤– Machine Learning Pipeline

Feature dataset built from curated indicators

Binary classification target: next-day price direction

Model: Logistic Regression (baseline)

Training data capped to avoid Spark â†’ Pandas memory issues

Artifacts saved with metadata

Example output:

models/stock_direction/v1/
â”œâ”€â”€ model.pkl
â””â”€â”€ metadata.json

ğŸŒ Model Serving (FastAPI)

A lightweight prediction service exposes:

GET /health

POST /predict

Example request:

{
  "daily_return": 0.012,
  "ma_7": 1510.5,
  "ma_14": 1505.3,
  "ma_30": 1498.8,
  "volatility_14": 0.018
}


Response:

{
  "prediction": 1,
  "probability": 0.56,
  "model_version": "v1"
}

ğŸ” CI/CD with Jenkins

The Jenkins pipeline enforces:

Environment setup

Data ingestion

Spark processing

Feature engineering

Model training

Smoke tests

All steps are fully automated and fail-fast.

ğŸš€ How to Run Locally
1ï¸âƒ£ Create virtual environment
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

2ï¸âƒ£ Run pipeline manually
scripts/run_ingestion.sh
scripts/run_processing.sh
scripts/run_indicators.sh
scripts/run_training.sh

3ï¸âƒ£ Start API
uvicorn src.serving.api:app --reload

ğŸ§ª Testing & Validation

Schema validation during ingestion

Value validation for stock prices

Smoke tests in CI

Partition pruning verified via Spark explain plans

ğŸ¯ Key Engineering Highlights

OOP + SOLID principles

Incremental Spark pipelines

Metadata-driven processing

Partition pruning optimization

Safe Spark â†’ Pandas boundary handling

CI/CD automation

Clean Git hygiene

ğŸ“Œ Future Improvements

Dockerization

Nginx reverse proxy

Model version promotion

Feature drift detection

Backtesting framework

Cloud deployment (optional)

ğŸ‘¤ Author

Built by thebluesurf3r
(Data Engineer | Python | Spark | ML Systems)